{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_doctors_review_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1dk9OkUsnZc"
      },
      "source": [
        "# Generating german doctor reviews with a GPT-2 model\n",
        "## Fine tuning of a pretrained **Hugging Face** transfomer decoder\n",
        "In this notebook we will be using a GPT-2 mdoel that was fine-tuned to synthesize doctor reviews mimiking actual patients' text comments.\n",
        "\n",
        "A detailed description of the **German language reviews of doctors by patients 2019** dataset can be found [here](https://data.world/mc51/german-language-reviews-of-doctors-by-patients)\n",
        "\n",
        "\n",
        "For this exercise, we will use the [**Hugging Face**](https://huggingface.co/) implementation of transformers for Tensorflow 2.0. Transformers provides a general architecture implementation for several state of the art models in the natural language domain.\n",
        "\n",
        "NOTE: This notebook and its implementation is heavily influenced by the [data-drive](https://data-dive.com/) *Natural Language Processing of German texts* blog post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqTxWLHouAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b07e46-b97b-465c-cb9a-12c4f193b0e4"
      },
      "source": [
        "!pip install -U transformers==4.9.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.9.2\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 26.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (4.62.2)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.9.2) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.2) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.9.2) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_fTsD6Lp49I"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import AutoTokenizer, TFGPT2LMHeadModel\n",
        "\n",
        "pd.options.display.max_colwidth = 600\n",
        "pd.options.display.max_rows = 400"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoNm6fYGtFv6"
      },
      "source": [
        "## Setting up the decoder model\n",
        "HuggingFace's transfomer library allows for conviniently loading  pre-configured text tokenizers and pre-trained models from local resources.\n",
        "\n",
        "Here we will be using a tokenizer and a GPT-2 model that was pre-trained on the doctor review dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAmgz3Rr6_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6a557f-7c00-4e87-85fb-489013d23aa6"
      },
      "source": [
        "!rm -r gpt2_doctorreview_finetuned* __MACOSX\n",
        "!gdown https://drive.google.com/uc?id=13wbf5bsLmvRFD-AgbmruWo6bdiyjkwd9 -O gpt2_doctorreview_finetuned.zip\n",
        "!unzip gpt2_doctorreview_finetuned.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-20 14:16:30--  https://github.com/AdvancedNLP/decoder/raw/main/gpt2_doctorreview_finetuned.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/AdvancedNLP/decoder/main/gpt2_doctorreview_finetuned.zip [following]\n",
            "--2021-09-20 14:16:30--  https://media.githubusercontent.com/media/AdvancedNLP/decoder/main/gpt2_doctorreview_finetuned.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 462732204 (441M) [application/zip]\n",
            "Saving to: ‘gpt2_doctorreview_finetuned.zip’\n",
            "\n",
            "gpt2_doctorreview_f 100%[===================>] 441.29M   163MB/s    in 2.7s    \n",
            "\n",
            "2021-09-20 14:16:44 (163 MB/s) - ‘gpt2_doctorreview_finetuned.zip’ saved [462732204/462732204]\n",
            "\n",
            "Archive:  gpt2_doctorreview_finetuned.zip\n",
            "   creating: gpt2_doctorreview_finetuned/\n",
            "  inflating: gpt2_doctorreview_finetuned/.DS_Store  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/._.DS_Store  \n",
            "   creating: gpt2_doctorreview_finetuned/tokenizer/\n",
            "   creating: gpt2_doctorreview_finetuned/model/\n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/added_tokens.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._added_tokens.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/tokenizer_config.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._tokenizer_config.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/special_tokens_map.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._special_tokens_map.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/tokenizer.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._tokenizer.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/merges.txt  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._merges.txt  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/vocab.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._vocab.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/model/config.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/model/._config.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/model/tf_model.h5  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/model/._tf_model.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZWMXIHmsDzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290b73ac-55d1-41d2-cbf9-a1eebe911d21"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('gpt2_doctorreview_finetuned/tokenizer')\n",
        "model = TFGPT2LMHeadModel.from_pretrained('gpt2_doctorreview_finetuned/model')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2_doctorreview_finetuned/model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp158R8YyP5V"
      },
      "source": [
        "## Generating doctor reviews\n",
        "The model has been conditioned to be able to control if positive or negative reviews should be generated. \n",
        "\n",
        "As an auto-regressive model the sequence is generated by building up from the passed input sequences. We can use this to control the polarity of the review by passing either the token for positive or for negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0TUof0E3NLP"
      },
      "source": [
        "POS_TOKEN = \"<|review_pos|>\"\n",
        "NEG_TOKEN = \"<|review_neg|>\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bH8NmbrHYj8"
      },
      "source": [
        "### Simple greedy search\n",
        "Let's implement our own greedy-search-based text generator. Generation happens in a loop where one token is generated at a time. Token with highest probability is select in each iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0JbcK0Hcqj"
      },
      "source": [
        "def generate_greedy(inputs:str, max_length=15):\n",
        "    #print('Input: ', inputs)\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors='tf')\n",
        "\n",
        "    for __ in range(max_length):\n",
        "        \n",
        "        logits = model.predict(input_ids).logits\n",
        "\n",
        "        ##########################\n",
        "        ## YOUR CODE HERE START ##\n",
        "        ##########################\n",
        "\n",
        "        # retrieve the predicted logits for the *last* token\n",
        "        # Dimensions are [batch_size, input_tokens, vocab_size]\n",
        "        next_token_logits = logits[:, -1, :]  \n",
        "\n",
        "        # Select the token with the highest probability and convert it to tf.int32\n",
        "        next_token = tf.math.argmax(next_token_logits, axis=-1, output_type=tf.int32)\n",
        "\n",
        "        # Concat the previous tokens with the new one\n",
        "        # You will have to expand the dimension of the next token to match \n",
        "        # the shape of input_ids\n",
        "        input_ids = tf.concat([input_ids, tf.expand_dims(next_token, -1)], 1)\n",
        "\n",
        "    output_ids = input_ids.numpy().squeeze()\n",
        "\n",
        "    ### Use your tokenizer to convert the output ids into text\n",
        "    decoded = tokenizer.decode(output_ids)\n",
        "\n",
        "    ##########################\n",
        "    ## YOUR CODE HERE END ##\n",
        "    ##########################\n",
        "    return decoded"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KJQ44yf1H_GH",
        "outputId": "9b70fecd-67bc-41c2-ad2b-0d8f8ee5ffa3"
      },
      "source": [
        "generate_greedy(POS_TOKEN + ' Ich', max_length=15)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|review_pos|> Ich bin seit Jahren bei Dr. Heuer in Behandlung und bin sehr zufrieden.'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6J10wZXfxDf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnqHWi9U0fnQ"
      },
      "source": [
        "### More advanced text generation\n",
        "So far so good. Now we understand how text can be generated.\n",
        "\n",
        "However we ignore when our model predicts EOS (end-of-sentence). What would be neccessary to incoorporate this in our function?\n",
        "\n",
        "What if we would want to generate multiple different review comments?\n",
        "Did you generate long reviews? Have you started to see repetitions in the generated output? Why is that?\n",
        "\n",
        "Luckily the Hugging Face implementation offers various ways for us to generate higher quality reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s8ock9e3x7S"
      },
      "source": [
        "#### Greedy search\n",
        "The following code can be used to generate text using a greedy search algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7I4kKh0OGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "5e83e4f4-3618-45db-c47a-47de28d0c924"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode(POS_TOKEN, return_tensors='tf')\n",
        "\n",
        "# generate text until the output length\n",
        "# (which includes the context length) reaches 50 \n",
        "greedy_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50,\n",
        "    num_return_sequences=3,\n",
        "    )\n",
        "\n",
        "genrated_reviews = [{'generated_text': tokenizer.decode(output, skip_special_tokens=True)}\n",
        "                    for output in greedy_outputs]\n",
        "pd.DataFrame(genrated_reviews)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wir haben uns während unserer Kinderwunschbehandlung sehr gut aufgehoben gefühlt Die Betreuung durch Dr. Kempkensteffen war ausgezeichnet und sein liebes Team arbeitet Hand in Hand aufeinander abgestimmt und engagiert. Wir können ihn bestens weiterempfehlen und würden Ihn jedem weiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ich bin seit Jahre zufriedene Patientin von Frau Dr. Sünter. Sie ist eine sehr kompetente Ärztin, die sich Zeit für ihre Patienten nimmt.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Die Wartezeit betrug ca. Minuten für einen Termin. Der Arzt hat sich Zeit genommen und alle Fragen beantwortet. Die Behandlung habe ich als sehr kompetent empfunden.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                   generated_text\n",
              "0   Wir haben uns während unserer Kinderwunschbehandlung sehr gut aufgehoben gefühlt Die Betreuung durch Dr. Kempkensteffen war ausgezeichnet und sein liebes Team arbeitet Hand in Hand aufeinander abgestimmt und engagiert. Wir können ihn bestens weiterempfehlen und würden Ihn jedem weiter\n",
              "1                                                                                                                                                       Ich bin seit Jahre zufriedene Patientin von Frau Dr. Sünter. Sie ist eine sehr kompetente Ärztin, die sich Zeit für ihre Patienten nimmt.\n",
              "2                                                                                                                           Die Wartezeit betrug ca. Minuten für einen Termin. Der Arzt hat sich Zeit genommen und alle Fragen beantwortet. Die Behandlung habe ich als sehr kompetent empfunden."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdKzZbwZ1_fP"
      },
      "source": [
        "#### Beam search \n",
        "Beam search can be considered as an alternative. At each step of generating a token, a set of top probability tokens are kept as part of the beam instead of just the highest-probability token. The sequence with the highest overall probability is returned at the end of the generation.\n",
        "\n",
        "What do the parameters `no_repeat_ngram_size` and `temperature` control?\n",
        "\n",
        "Generating text using beam search is done like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gARjZeRd02rK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "91d41185-b43f-4504-c75d-a9ca5451c9f8"
      },
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_beams=7,\n",
        "    no_repeat_ngram_size=3,\n",
        "    num_return_sequences=3,\n",
        "    early_stopping=True,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "genrated_reviews = [{'generated_text': tokenizer.decode(output, skip_special_tokens=True)}\n",
        "                    for output in beam_outputs]\n",
        "pd.DataFrame(genrated_reviews)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ich bin seit Jahren bei Dr. Heuer in Behandlung und bin sehr zufrieden. Er ist sehr kompetent und nimmt sich Zeit für seine Patienten. Ich kann ihn nur weiterempfehlen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                               generated_text\n",
              "0    Ich bin seit Jahren bei Dr. Heuer in Behandlung und bin sehr zufrieden. Er ist sehr kompetent und nimmt sich Zeit für seine Patienten. Ich kann ihn nur weiterempfehlen.\n",
              "1   Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.\n",
              "2   Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-6EYxJDy6pq"
      },
      "source": [
        "#### High level pipeline\n",
        "The easiest way to to use the model is to use HuggingFaces transformer `pipeline` implementation to encapsulate the previously loaded `model` and `tokenizer`.\n",
        "\n",
        "The documentation for the [**pipeline**](https://huggingface.co/transformers/main_classes/pipelines.html) abstraction describes how to do the setup.\n",
        "\n",
        "While being able to generate reviews with very high fiddelity, it's also the slowest approach. Can you find out why?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xaNvHGq5u9F"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oa024P7zzVy"
      },
      "source": [
        "##########################\n",
        "## YOUR CODE HERE START ##\n",
        "##########################\n",
        "# build a transformer-pipeline \n",
        "# to generate text using the \n",
        "# previously loaded model and tokenizer\n",
        "\n",
        "review_generator = pipeline(\n",
        "  \"text-generation\",\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "##########################\n",
        "## YOUR CODE HERE END   ##\n",
        "##########################"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhj8_NG_ms2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "224cc0bd-9c75-4c61-da18-b8b620fffa4a"
      },
      "source": [
        "pos_generated_reviews = review_generator(POS_TOKEN, max_length=50, num_return_sequences=3)\n",
        "pd.DataFrame(pos_generated_reviews)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|review_pos|&gt; Herr Dr. Plöger hat mich äußerst freundlich und kompetent behandelt. Er hat sich viel Zeit für mein Anliegen genommen und auch eine individuelle und umfassende Beratung durchgeführt. Ich hatte gleich ein gutes Gefühl. Ich kann diese Praxis zu weiterempfehlen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|review_pos|&gt; Seit Jahren bin ich bei Herrn Dr. Schwarz in Behandlung und kann ihn nur wärmstens weiterempfehlen. Sein Team ist kompetent und immer freundlich.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|review_pos|&gt; Herr Dr. Runge war immer der mein Hausarzt. Sehr zuvorkommend, nett, hilfsbereit und freundlich. Ich kann ihn mit bestem Gewissen empfehlen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                       generated_text\n",
              "0  <|review_pos|> Herr Dr. Plöger hat mich äußerst freundlich und kompetent behandelt. Er hat sich viel Zeit für mein Anliegen genommen und auch eine individuelle und umfassende Beratung durchgeführt. Ich hatte gleich ein gutes Gefühl. Ich kann diese Praxis zu weiterempfehlen.\n",
              "1                                                                                                                    <|review_pos|> Seit Jahren bin ich bei Herrn Dr. Schwarz in Behandlung und kann ihn nur wärmstens weiterempfehlen. Sein Team ist kompetent und immer freundlich.\n",
              "2                                                                                                                          <|review_pos|> Herr Dr. Runge war immer der mein Hausarzt. Sehr zuvorkommend, nett, hilfsbereit und freundlich. Ich kann ihn mit bestem Gewissen empfehlen"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxN9_D_Nm3jT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c91279cb-0252-44b4-d1b0-5ad7865ca10b"
      },
      "source": [
        "neg_generated_reviews = review_generator(NEG_TOKEN, max_length=50, num_return_sequences=3)\n",
        "pd.DataFrame(neg_generated_reviews)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|review_neg|&gt; Ich werde nicht mit meinem Kind zum Arzt gehen !!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|review_neg|&gt; Ich war bei dieser Ärztin ein Jahr . Sie ist sehr freundlich und nimmt sich Zeit für ihre Patienten. In meinen Augen war sie inkompetent, überlässt einem das Gefühl nicht zufrieden zu sein und hat mir keine Zeit gegeben mich zu untersuchen. Die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|review_neg|&gt; Ich war zur Untersuchung dort und wollte mir eine zweite Meinung einholen. Er hatte eine sehr hohe Anzahl an Bewertungen und dadurch hatte ich mich für eine Praxis entschieden, bei der ich die Praxis war. Ich habe ein paar Minuten mit dem Arzt verbracht,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                  generated_text\n",
              "0                                                                                                                                                                                                               <|review_neg|> Ich werde nicht mit meinem Kind zum Arzt gehen !!\n",
              "1            <|review_neg|> Ich war bei dieser Ärztin ein Jahr . Sie ist sehr freundlich und nimmt sich Zeit für ihre Patienten. In meinen Augen war sie inkompetent, überlässt einem das Gefühl nicht zufrieden zu sein und hat mir keine Zeit gegeben mich zu untersuchen. Die\n",
              "2  <|review_neg|> Ich war zur Untersuchung dort und wollte mir eine zweite Meinung einholen. Er hatte eine sehr hohe Anzahl an Bewertungen und dadurch hatte ich mich für eine Praxis entschieden, bei der ich die Praxis war. Ich habe ein paar Minuten mit dem Arzt verbracht,"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6I4ebPhpA0"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}