{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_doctors_review_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1dk9OkUsnZc"
      },
      "source": [
        "# Generating german doctor reviews with a GPT-2 model\n",
        "## Fine tuning of a pretrained **Hugging Face** transfomer decoder\n",
        "In this notebook we will be using a GPT-2 mdoel that was fine-tuned to synthesize doctor reviews mimiking actual patients' text comments.\n",
        "\n",
        "A detailed description of the **German language reviews of doctors by patients 2019** dataset can be found [here](https://data.world/mc51/german-language-reviews-of-doctors-by-patients)\n",
        "\n",
        "\n",
        "For this exercise, we will use the [**Hugging Face**](https://huggingface.co/) implementation of transformers for Tensorflow 2.0. Transformers provides a general architecture implementation for several state of the art models in the natural language domain.\n",
        "\n",
        "NOTE: This notebook and its implementation is heavily influenced by the [data-drive](https://data-dive.com/) *Natural Language Processing of German texts* blog post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqTxWLHouAC",
        "outputId": "d3b91868-9385-4b93-d44a-4829cffcdcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U transformers==4.9.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.9.2 in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (4.62.2)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (0.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.2) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.9.2) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.2) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.9.2) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.2) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.2) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_fTsD6Lp49I"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import AutoTokenizer, TFGPT2LMHeadModel\n",
        "\n",
        "pd.options.display.max_colwidth = 600\n",
        "pd.options.display.max_rows = 400"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoNm6fYGtFv6"
      },
      "source": [
        "## Setting up the decoder model\n",
        "HuggingFace's transfomer library allows for conviniently loading  pre-configured text tokenizers and pre-trained models from local resources.\n",
        "\n",
        "Here we will be using a tokenizer and a GPT-2 model that was pre-trained on the doctor review dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAmgz3Rr6_W",
        "outputId": "6d922ed8-292e-465d-dde8-05b891c42321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -O gpt2_doctorreview_finetuned.zip https://github.com/AdvancedNLP/decoder/raw/main/gpt2_doctorreview_finetuned.zip\n",
        "!unzip gpt2_doctorreview_finetuned.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-20 13:54:01--  https://github.com/AdvancedNLP/decoder/raw/main/gpt2_doctorreview_finetuned.zip\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/AdvancedNLP/decoder/main/gpt2_doctorreview_finetuned.zip [following]\n",
            "--2021-09-20 13:54:02--  https://media.githubusercontent.com/media/AdvancedNLP/decoder/main/gpt2_doctorreview_finetuned.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 462732204 (441M) [application/zip]\n",
            "Saving to: ‘gpt2_doctorreview_finetuned.zip’\n",
            "\n",
            "gpt2_doctorreview_f 100%[===================>] 441.29M   142MB/s    in 3.2s    \n",
            "\n",
            "2021-09-20 13:54:30 (139 MB/s) - ‘gpt2_doctorreview_finetuned.zip’ saved [462732204/462732204]\n",
            "\n",
            "Archive:  gpt2_doctorreview_finetuned.zip\n",
            "replace gpt2_doctorreview_finetuned/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/gpt2_doctorreview_finetuned/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace gpt2_doctorreview_finetuned/tokenizer/added_tokens.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._added_tokens.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._added_tokens.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/tokenizer_config.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._tokenizer_config.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/special_tokens_map.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._special_tokens_map.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/tokenizer.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._tokenizer.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/merges.txt  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._merges.txt  \n",
            "  inflating: gpt2_doctorreview_finetuned/tokenizer/vocab.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/tokenizer/._vocab.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/model/config.json  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/model/._config.json  \n",
            "  inflating: gpt2_doctorreview_finetuned/model/tf_model.h5  \n",
            "  inflating: __MACOSX/gpt2_doctorreview_finetuned/model/._tf_model.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZWMXIHmsDzg",
        "outputId": "7bafe8c0-de51-4745-8de3-907f4d797ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('gpt2_doctorreview_finetuned/tokenizer')\n",
        "model = TFGPT2LMHeadModel.from_pretrained('gpt2_doctorreview_finetuned/model')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2_doctorreview_finetuned/model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp158R8YyP5V"
      },
      "source": [
        "## Generating doctor reviews\n",
        "The model has been conditioned to be able to control if positive or negative reviews should be generated. \n",
        "\n",
        "As an auto-regressive model the sequence is generated by building up from the passed input sequences. We can use this to control the polarity of the review by passing either the token for positive or for negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0TUof0E3NLP"
      },
      "source": [
        "POS_TOKEN = \"<|review_pos|>\"\n",
        "NEG_TOKEN = \"<|review_neg|>\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bH8NmbrHYj8"
      },
      "source": [
        "### Simple greedy search\n",
        "Let's implement our own greedy-search-based text generator. Generation happens in a loop where one token is generated at a time. Token with highest probability is select in each iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_0JbcK0Hcqj"
      },
      "source": [
        "def generate_greedy(inputs:str, max_length=15):\n",
        "    #print('Input: ', inputs)\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors='tf')\n",
        "\n",
        "    for __ in range(max_length):\n",
        "        \n",
        "        logits = model.predict(input_ids).logits\n",
        "\n",
        "        ##########################\n",
        "        ## YOUR CODE HERE START ##\n",
        "        ##########################\n",
        "\n",
        "        # retrieve the predicted logits for the *last* token\n",
        "        # Dimensions are [batch_size, input_tokens, vocab_size]\n",
        "        next_token_logits = logits[:, -1, :]  \n",
        "\n",
        "        # Select the token with the highest probability\n",
        "        next_token = tf.math.argmax(next_token_logits, axis=-1, output_type=tf.int32)\n",
        "\n",
        "        # Combine the previous tokens with the new one\n",
        "        input_ids = tf.concat([input_ids, tf.expand_dims(next_token, -1)], 1)\n",
        "\n",
        "        ##########################\n",
        "        ## YOUR CODE HERE END ##\n",
        "        ##########################\n",
        "\n",
        "    decoded = tokenizer.decode(input_ids.numpy().squeeze(), skip_special_tokens=False)\n",
        "\n",
        "    return decoded"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJQ44yf1H_GH",
        "outputId": "71654187-0dcb-4177-a27f-b89481e33a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "generate_greedy(POS_TOKEN + ' Ich', max_length=15)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  <|review_pos|> Ich\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|review_pos|> Ich bin seit Jahren bei Dr. Heuer in Behandlung und bin sehr zufrieden.'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6J10wZXfxDf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnqHWi9U0fnQ"
      },
      "source": [
        "### More advanced text generation\n",
        "So far so good. Now we understand how text can be generated.\n",
        "\n",
        "However we ignore when our model predicts EOS (end-of-sentence). What would be neccessary to incoorporate this in our function?\n",
        "\n",
        "What if we would want to generate multiple different review comments?\n",
        "Did you generate long reviews? Have you started to see repetitions in the generated output? Why is that?\n",
        "\n",
        "Luckily the Hugging Face implementation offers various ways for us to generate higher quality reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s8ock9e3x7S"
      },
      "source": [
        "#### Greedy search\n",
        "The following code can be used to generate text using a greedy search algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7I4kKh0OGJ",
        "outputId": "804822c2-b3ff-462c-d0f2-c29296aa2050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode(POS_TOKEN, return_tensors='tf')\n",
        "\n",
        "# generate text until the output length\n",
        "# (which includes the context length) reaches 50 \n",
        "greedy_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50,\n",
        "    num_return_sequences=3,\n",
        "    )\n",
        "\n",
        "genrated_reviews = [{'generated_text': tokenizer.decode(output, skip_special_tokens=True)}\n",
        "                    for output in greedy_outputs]\n",
        "pd.DataFrame(genrated_reviews)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Das Praxisteam ist sehr lieb und freundlich. Frau Dr. Marqwardt nimmt sich stets Zeit um alles zu erklären und ist sehr einfühlsam. Sie hat mich schon in vielen Situationen gut begleitet und sich viel Mühe gegeben. Ich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ich habe sofort einen Termin bekommen und bin wirklich begeistert! Es ging schnell und reibungslos!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dr. Krug ist nur weiter zu empfehlen er kümmert sich sehr um seine kleinen Patienten ist auch sehr höflich, gibt viele Anregungen und kümmert sich sehr gut um deren Wohlergehen und Problemen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                generated_text\n",
              "0   Das Praxisteam ist sehr lieb und freundlich. Frau Dr. Marqwardt nimmt sich stets Zeit um alles zu erklären und ist sehr einfühlsam. Sie hat mich schon in vielen Situationen gut begleitet und sich viel Mühe gegeben. Ich\n",
              "1                                                                                                                          Ich habe sofort einen Termin bekommen und bin wirklich begeistert! Es ging schnell und reibungslos!\n",
              "2                               Dr. Krug ist nur weiter zu empfehlen er kümmert sich sehr um seine kleinen Patienten ist auch sehr höflich, gibt viele Anregungen und kümmert sich sehr gut um deren Wohlergehen und Problemen"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdKzZbwZ1_fP"
      },
      "source": [
        "#### Beam search \n",
        "Beam search can be considered as an alternative. At each step of generating a token, a set of top probability tokens are kept as part of the beam instead of just the highest-probability token. The sequence with the highest overall probability is returned at the end of the generation.\n",
        "\n",
        "What do the parameters `no_repeat_ngram_size` and `temperature` control?\n",
        "\n",
        "Generating text using beam search is done like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gARjZeRd02rK",
        "outputId": "7ebf542c-b538-4076-9298-4ac31f5197a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "beam_outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_beams=7,\n",
        "    no_repeat_ngram_size=3,\n",
        "    num_return_sequences=3,\n",
        "    early_stopping=True,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "genrated_reviews = [{'generated_text': tokenizer.decode(output, skip_special_tokens=True)}\n",
        "                    for output in beam_outputs]\n",
        "pd.DataFrame(genrated_reviews)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent, freundlich und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                           generated_text\n",
              "0   Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent, freundlich und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.\n",
              "1               Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben.\n",
              "2               Ich bin seit Jahren bei Frau Dr. Henze und bin sehr zufrieden. Sie ist sehr kompetent und nimmt sich Zeit für ihre Patienten. Ich fühle mich bei ihr sehr gut aufgehoben."
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-6EYxJDy6pq"
      },
      "source": [
        "#### High level pipeline\n",
        "The easiest way to to use the model is to use HuggingFaces transformer `pipeline` implementation to encapsulate the previously loaded `model` and `tokenizer`.\n",
        "\n",
        "The documentation for the [**pipeline**](https://huggingface.co/transformers/main_classes/pipelines.html) abstraction describes how to do the setup.\n",
        "\n",
        "While being able to generate reviews with very high fiddelity, it's also the slowest approach. Can you find out why?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xaNvHGq5u9F"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oa024P7zzVy"
      },
      "source": [
        "##########################\n",
        "## YOUR CODE HERE START ##\n",
        "##########################\n",
        "# build a transformer-pipeline \n",
        "# to generate text using the \n",
        "# previously loaded model and tokenizer\n",
        "\n",
        "review_generator = pipeline(\n",
        "  \"text-generation\",\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "##########################\n",
        "## YOUR CODE HERE END   ##\n",
        "##########################"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhj8_NG_ms2T",
        "outputId": "f8cc5606-fb49-4a25-d2fe-9090eb89f687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "pos_generated_reviews = review_generator(POS_TOKEN, max_length=50, num_return_sequences=3)\n",
        "pd.DataFrame(pos_generated_reviews)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|review_pos|&gt; Frau Dr. Runge nimmt sich Zeit, berät umfassend und bietet auch alternative Heilungsmöglichkeiten an. Frau Dr. Runge hört aufmerksam zu. Sie hat eine vertrauensvolle Art, in der ich mich sehr gut aufgehoben fühle. Zudem wird auch mal ein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|review_pos|&gt; Wir sind seit Jahren sehr zufrieden mit Frau Dr. Riegsinger. Sie ist eine sehr nette, einfühlsame Ärztin, die sich immer Zeit nimmt und alles sehr genau und verständlich erklärt. Wir sind sehr zufrieden und können sie nur empfehlen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|review_pos|&gt; Dr Feichel ist ein sehr netter, kompetenter und erfahrener Arzt, der weiß was er tut. Er nimmt sich immer Zeit für seine Patienten.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                 generated_text\n",
              "0  <|review_pos|> Frau Dr. Runge nimmt sich Zeit, berät umfassend und bietet auch alternative Heilungsmöglichkeiten an. Frau Dr. Runge hört aufmerksam zu. Sie hat eine vertrauensvolle Art, in der ich mich sehr gut aufgehoben fühle. Zudem wird auch mal ein\n",
              "1       <|review_pos|> Wir sind seit Jahren sehr zufrieden mit Frau Dr. Riegsinger. Sie ist eine sehr nette, einfühlsame Ärztin, die sich immer Zeit nimmt und alles sehr genau und verständlich erklärt. Wir sind sehr zufrieden und können sie nur empfehlen.\n",
              "2                                                                                                            <|review_pos|> Dr Feichel ist ein sehr netter, kompetenter und erfahrener Arzt, der weiß was er tut. Er nimmt sich immer Zeit für seine Patienten."
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxN9_D_Nm3jT",
        "outputId": "4f9a8756-198d-4594-883f-bd5b9fdaffa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "neg_generated_reviews = review_generator(NEG_TOKEN, max_length=50, num_return_sequences=3)\n",
        "pd.DataFrame(neg_generated_reviews)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|review_neg|&gt; Nachdem mein Hausarzt seine Ausbildung über Jahre gemacht hat, habe ich mich nach einer Empfehlung einer Bekannten in die Praxis von Frau Dr. Pustelnik begeben. Nach dem ersten Termin für meine Lungenfachärztin bin ich ohne Wartezeit schon ins Sprechzimmer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|review_neg|&gt; Trotz vorherigem Telefonat wurde ich unfreundlich behandelt, und musste dann noch eine Ewigkeit warten, obwohl ich mir für eine Überweisung nur auf einen anderen Arzttermin warte. Die Schwestern machen einen nicht gerade einmal richtig. Der Arzt selbst ist sehr nett</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|review_neg|&gt; Sie nimmt sich keine Zeit, redet nur über das was sie kann. Man kann nix anderes erwarten. Sie hat kein Mitgefühl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                              generated_text\n",
              "0            <|review_neg|> Nachdem mein Hausarzt seine Ausbildung über Jahre gemacht hat, habe ich mich nach einer Empfehlung einer Bekannten in die Praxis von Frau Dr. Pustelnik begeben. Nach dem ersten Termin für meine Lungenfachärztin bin ich ohne Wartezeit schon ins Sprechzimmer\n",
              "1  <|review_neg|> Trotz vorherigem Telefonat wurde ich unfreundlich behandelt, und musste dann noch eine Ewigkeit warten, obwohl ich mir für eine Überweisung nur auf einen anderen Arzttermin warte. Die Schwestern machen einen nicht gerade einmal richtig. Der Arzt selbst ist sehr nett\n",
              "2                                                                                                                                                        <|review_neg|> Sie nimmt sich keine Zeit, redet nur über das was sie kann. Man kann nix anderes erwarten. Sie hat kein Mitgefühl..."
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6I4ebPhpA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}